/**
 * overpassQueue.ts
 *
 * Global Overpass API request queue â€” manages concurrent Overpass requests
 * across the ENTIRE app, spreading load across multiple servers.
 *
 * All three Overpass callers (nearbyCache.ts, safety.ts, safetyMapData.ts)
 * import this single queue so they share concurrency control.
 *
 * Features:
 *   â€¢ Concurrent queue â€” up to 3 requests in-flight (one per server)
 *   â€¢ 80ms cooldown between requests to stay polite
 *   â€¢ 3-server round-robin: overpass-api.de â†’ kumi.systems â†’ mail.ru
 *   â€¢ Per-request timeout with AbortController
 *   â€¢ Retry on 429 / 5xx before trying next server
 */

import { env } from '@/src/config/env';

// â”€â”€â”€ Overpass servers (with fallbacks) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const OVERPASS_SERVERS = [
  env.overpassBaseUrl,
  'https://overpass.kumi.systems/api/interpreter',
  'https://maps.mail.ru/osm/tools/overpass/api/interpreter',
];

// â”€â”€â”€ Queue state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const MAX_CONCURRENT = 3;  // up to 3 in-flight requests (spread across servers)
let inflight = 0;
const waiting: Array<() => void> = [];
let lastRequestTime = 0;
const MIN_GAP_MS = 80; // minimum ms between dispatches (polite pacing)

// â”€â”€â”€ Stats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let totalCalls = 0;
let queuedCalls = 0;

/**
 * Low-level fetch: tries all Overpass servers in order for a single request.
 * Handles 429 / 5xx by moving to the next server.
 */
const fetchWithFallback = async (
  body: string,
  timeoutMs: number,
): Promise<any> => {
  let lastError: Error | null = null;

  for (const server of OVERPASS_SERVERS) {
    try {
      const controller = new AbortController();
      const timer = setTimeout(() => controller.abort(), timeoutMs);

      const response = await fetch(server, {
        method: 'POST',
        headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
        body,
        signal: controller.signal,
      });

      clearTimeout(timer);

      if (response.status === 429) {
        console.warn(`[OverpassQ] ${server} â†’ 429 rate-limited, trying nextâ€¦`);
        lastError = new Error(`HTTP 429 from ${server}`);
        continue;
      }
      if (response.status >= 500) {
        console.warn(`[OverpassQ] ${server} â†’ ${response.status}, trying nextâ€¦`);
        lastError = new Error(`HTTP ${response.status} from ${server}`);
        continue;
      }
      if (!response.ok) {
        console.warn(`[OverpassQ] ${server} â†’ ${response.status}`);
        lastError = new Error(`HTTP ${response.status} from ${server}`);
        continue;
      }

      return await response.json();
    } catch (err) {
      const msg = err instanceof Error ? err.message : String(err);
      if (msg.includes('AbortError') || msg.includes('aborted')) {
        console.warn(`[OverpassQ] ${server} â†’ timeout (${timeoutMs}ms), trying nextâ€¦`);
      } else {
        console.warn(`[OverpassQ] ${server} â†’ ${msg}, trying nextâ€¦`);
      }
      lastError = err instanceof Error ? err : new Error(msg);
      continue;
    }
  }

  // All servers failed
  console.error('[OverpassQ] All Overpass servers failed');
  throw lastError ?? new Error('All Overpass servers failed');
};

/**
 * Queue an Overpass request. Requests run one-at-a-time with a cooldown
 * between them so we never spam the server.
 *
 * @param body   - URL-encoded POST body (e.g. "data=<Overpass QL>")
 * @param timeoutMs - per-request timeout (default 15s)
 * @param label  - optional label for debug logging
 * @returns Parsed JSON response
 *
 * Throws if ALL three servers fail for this request.
 */
export const queueOverpassRequest = async <T = any>(
  body: string,
  timeoutMs = 15_000,
  label = '',
): Promise<T> => {
  totalCalls++;
  const callNum = totalCalls;
  const logLabel = label ? ` (${label})` : '';

  // Wait for a concurrency slot
  if (inflight >= MAX_CONCURRENT) {
    await new Promise<void>((resolve) => waiting.push(resolve));
  }

  // Enforce minimum gap between dispatches
  const elapsed = Date.now() - lastRequestTime;
  if (elapsed < MIN_GAP_MS) {
    await new Promise((r) => setTimeout(r, MIN_GAP_MS - elapsed));
  }

  inflight++;
  lastRequestTime = Date.now();
  queuedCalls++;
  console.log(`[OverpassQ] ðŸŒ #${callNum}${logLabel} | inflight: ${inflight}/${MAX_CONCURRENT}, total: ${totalCalls}`);

  try {
    return await fetchWithFallback(body, timeoutMs) as T;
  } finally {
    inflight--;
    // Release next waiter if any
    if (waiting.length > 0) {
      const next = waiting.shift()!;
      next();
    }
  }
};

/**
 * Convenience: build body from a query string and queue it.
 */
export const queueOverpassQuery = async <T = any>(
  query: string,
  timeoutMs = 15_000,
  label = '',
): Promise<T> => {
  const body = `data=${encodeURIComponent(query)}`;
  return queueOverpassRequest<T>(body, timeoutMs, label);
};
